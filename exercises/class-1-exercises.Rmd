---
title: "Exercises for class 1"
output: html_document
date: "13-02-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rethinking)
```

# Exercises for Class 1

## Supporting code

Below is code from Chapter 2 of the book that you can use to do the exercises. Not all the code you require is here though. Make sure to not rush it and take time to play around with each function. :))

```{r}
# Grid Approximation

# define grid
p_grid = seq(from = 0, to = 1, length.out=20)

# define prior
prior = rep(1, 20)

# compute likelihood at each value in grid
likelihood = dbinom(6, size = 9, prob = p_grid)

# compute product of likelihood and prior
unstd.posterior = likelihood * prior

# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

```

## Exercises

### Easy

2E1. 

Which of the expressions below correspond to the statement: the probability of rain on Monday?
(1) Pr(rain)
(2) Pr(rain|Monday) -> this one 
(3) Pr(Monday|rain)
(4) Pr(rain, Monday)/ Pr(Monday)

the probability of rain on Monday = the probability of rain given that it's Monday 

2E2.
Which of the following statements corresponds to the expression: Pr(Monday|rain)?
(1) The probability of rain on Monday.
(2) The probability of rain, given that it is Monday.
(3) The probability that it is Monday, given that it is raining. -> this one
(4) The probability that it is Monday and that it is raining.


2E3.
Which of the expressions below correspond to the statement: the probability that it is Monday,
given that it is raining?

(1) Pr(Monday|rain) -> this one 
(2) Pr(rain|Monday)
(3) Pr(rain|Monday) Pr(Monday)
(4) Pr(rain|Monday) Pr(Monday)/ Pr(rain)
(5) Pr(Monday|rain) Pr(rain)/ Pr(Monday)

2E4.

The Bayesian statistician Bruno de Finetti (1906–1985) began his book on probability theory with the declaration: “PROBABILITY DOES NOT EXIST.” The capitals appeared in the original, so I imagine de Finetti wanted us to shout this statement. What he meant is that probability is **a device for describing uncertainty from the perspective of an observer with limited knowledge; it has no objective reality**. Discuss the globe tossing example from the chapter, in light of this statement. What does it mean to say “the probability of water is 0.7”?


### Medium

2M1.

Recall the globe tossing model from the chapter. Compute and plot the grid approximate
posterior distribution for each of the following sets of observations. In each case, assume a uniform
prior for p.
(1) W, W, W
(2) W, W, W, L
(3) L, W, W, L, W, W, W

```{r}
# Grid Approximation

# define grid
p_grid = seq(from = 0, to = 1, length.out=20) 
#possible 'marble' combinations (considers all possibilities for combinations of colors in the bag - so considers all possibilities for combinations of water)

# define prior
prior = rep(1, 20)
#where you code your belief 

# compute likelihood at each value in grid
likelihood = dbinom(3, size = 3, prob = p_grid)
#dbinom(3, )=number of successes, as water is the success
#size = trials (here, times globe is thrown and caught)= 3
#prop = 0.3 - if the globe is x% water, what are the chances for observing 3 water when throwing it 3 times 

# compute product of likelihood and prior
unstd.posterior = likelihood * prior

# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")
```

2M2.

Now assume a prior for p that is equal to zero when p < 0.5 and is a positive constant when
p ≥ 0.5. Again compute and plot the grid approximate posterior distribution for each of the sets of
observations in the problem just above.

```{r}

# In the book, McElreath says that we can do much better than choosing a uniform prior for estimating the coverage of water. Is this what we are doing here? How does that impact our estimation?

```

2M3.

```{r}

# Use the Bayes formula!

```

For the exercises below, I highly suggest you to grab a piece of paper and try to solve the problems in a 'visual' way.

2M4.

```{r}

# Write your probability here.

```

2M5.

```{r}

# Write your probability here.

```

2M6.

```{r}

# Write your probability here.

```
